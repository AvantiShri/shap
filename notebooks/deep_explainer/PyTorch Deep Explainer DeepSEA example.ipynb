{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Deep Explainer DeepSEA example\n",
    "\n",
    "Running the pytorch Deep Explainer on the DeepSEA model from the kipoi repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we pull the kipoi pytorch model and load it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#pull the model from kipoi\n",
    "! [[ -f deepsea_model_architecture.py ]] || wget https://raw.githubusercontent.com/kipoi/models/master/DeepSEA/model_architecture.py -O deepsea_model_architecture.py\n",
    "! [[ -f deepsea_model_weights.pth ]] || wget https://zenodo.org/record/1466993/files/deepsea_variant_effects.pth?download=1 -O deepsea_model_weights.pth\n",
    "from deepsea_model_architecture import veff_model as pytorch_model, Lambda\n",
    "pytorch_model.load_state_dict(torch.load(\"deepsea_model_weights.pth\"))\n",
    "pytorch_model = pytorch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def gather_list_of_layers(module):\n",
    "    layers_list = []\n",
    "    for child in module.children():\n",
    "        if 'nn.modules.container' in str(type(child)):\n",
    "            layers_list.extend(gather_list_of_layers(child))\n",
    "        else:\n",
    "            layers_list.append(child)\n",
    "    return layers_list\n",
    "\n",
    "\n",
    "def create_interpretation_model(original_model, idx_to_select, prenonlinearity):\n",
    "    all_layers = gather_list_of_layers(original_model)\n",
    "    if (prenonlinearity):\n",
    "        all_layers = all_layers[:-1]\n",
    "    all_layers.append(Lambda(lambda x: x[:,idx_to_select:(idx_to_select+1)]))\n",
    "    interpretation_model = nn.Sequential(*all_layers)\n",
    "    return interpretation_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequences = [\n",
    "    \"GGCGATCCTTAGGCCTTGGCCCTGAGACCCCAGGCGAGGTCAGCAACCCAACCG\"\n",
    "    \"GGGTGGGACAGGACGAGCAAGAGGTTCTGCTCACGCATGTCCCCACTAACCTGG\"\n",
    "    \"CCGAGGGGCTCCCGCCCGGCTTATCCGGACTCCGGGCAGCCTCGCGTGCTTCCC\"\n",
    "    \"GTGTCTCCGCTTGTGGAGAATTTTCGGACTCGGATTCGGACTCGGAGTCAAAGC\"\n",
    "    \"CCGAAGCTAGGAACTCGTCCACCGTCAGCTCCGCCAGGCGCCTGCGGGTCACGC\"\n",
    "    \"AGGAGTCACAGCTGCCCGCACGCCCAGCTCGCCCCAGCCCCGCTGAGAGGAGCA\"\n",
    "    \"AGAAAAGCCCCCTTGGATACAGACACCCACCGGGAGGCCAAATCGGCCCTCGGA\"\n",
    "    \"CCCGCGGCTTACCTCTTGCGGCTCCCCGCAGCTGCCATGACACCAACCCGAAGC\"\n",
    "    \"GTGCACCCCACTTCCGGCCCCAGAATGCCGCGCGGCTGCGCACTTCCGccgccc\"\n",
    "    \"aggccccgcccctttccccgccccgccgcgccacgcccagccGAGTGGCTCTAT\"\n",
    "    \"GGTTCTCCGACCGCAACGCCGGCGGCCTCAGGGCGGGAGGGCGCGTTCGCGTGC\"\n",
    "    \"TCGGTGCGGGCAGCCCCGGTGGGGCCCAGATGCGCCTCCCGCTCGGCGCCCGGC\"\n",
    "    \"TCCGTAGGACGCGGTGACGCCGGTGTCCGCCCCGGGGAAGACCGGGAGTCCCGC\"\n",
    "    \"CGCGCCCGCAGCCCACCCGGCGCTCCGAAGGCACGCGCCTGCGAGGACGCCAGA\"\n",
    "    \"CTGCAACGGCGGGGCTCCTATGCAAAGAGCTCCCACAAATCAACAATAAAAAGC\"\n",
    "    \"AGGGAGTCCAGTGGAAAACGCGAGGGGCAGTGGGAACCGCACTGATGTCGCCAG\"\n",
    "    \"CTCGACAAAAGACGGGCGACCCGAGGGCCAGGCTGGCTTCGCCTCCGATCCGCG\"\n",
    "    \"GAGACCGGGCCAGCGCCACGAACACCACGCAGGGCGCTCCCCGTCCATGGCCCT\"\n",
    "    \"CTGGGTGCCGACCGCGGCTCTTCCCGGG\",\n",
    "    \"GGGCTGAGGGTGGCCGGGCGGCTGCACACTAGCTGGGTCGCGGCGCAGAAACGC\"\n",
    "    \"AGGGGCCGCGAGTGCGCTGGCCGGCGGGTGTCCCGGGTCCACGCTTACGGTCCT\"\n",
    "    \"CATGTTCTTTTTCTTCAGGTATCGGGCTTTGGTGCATTTCACAAAGGCTCGAAT\"\n",
    "    \"CACGGTTCTGACCGCCAACCTGTAGCAGCGATTTTTCCTTCCCCGGAAGTGCTG\"\n",
    "    \"GGACAGAAAACGAGAAACCAGGGTTGTCAgcggggcccgcgccggccgccccTT\"\n",
    "    \"GGCCCGCGGGATACCCCGGGCGCCCAGTGCCCAGGCCGGGCAGGCGGCACTCAC\"\n",
    "    \"CCTGGCGTGCTTCAGCACCTCCTGGATCCGAAAGTAGCGGTCGGTGACGCGATT\"\n",
    "    \"CCGCAGCCAGAGCTGCGCGGTGAGGAAGACCATGGCGCCTGCAGGCCGGCGTCC\"\n",
    "    \"CGAACACTCAACAACGCACGCGCAGCGCCGCTGCCATCTTGCCCGGGTCGGAAA\"\n",
    "    \"TGGTGGTCACGAGCGCTTCCGGGTCAGCCCCTGCGATACTTCCGGGGCGAAGGT\"\n",
    "    \"CGTCTCCCGTCAGCCCGCGGGTGCCCAGTTGTGCTCCTGAACTCGCGGTGGTGG\"\n",
    "    \"TGCGTGTTGGGGAGCGGATGTGGGGCCGCGGCGGGGACTGAAAGGAGAACGGGG\"\n",
    "    \"CCGCAGCGCCCGTGGCTATTCGCGGACGATGGATAAACAGCAGCGCACGCGGAC\"\n",
    "    \"CGTCCCGGAGCACGGCCCCGGCCGCAGCTGTGGCTCCGAGGGCACCGTGAGGGC\"\n",
    "    \"AGCGGACCCGGGTcgggggccccgcggccggggagctcgggtgcggcgcgggcg\"\n",
    "    \"gggaggggcaggccgcccccTGGGGCCACGAGGATGTTCAGGAACCGAGGTGGA\"\n",
    "    \"GATGGTCGCATCGGTGTGAAAGTGCCCGTTGCCTCTGAACCTTGCACtttgttt\"\n",
    "    \"acttactcattttgagacggggtctcgcccggtcgccctggctggggtgcagcg\"\n",
    "    \"gcccgacctcggctcgccgcggcctctg\"\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for one-hot encoding\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "#this is set up for 1d convolutions where examples\n",
    "#have dimensions (len, num_channels)\n",
    "#the channel axis is the axis for one-hot encoding.\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return.transpose((1,0))[:,None,:]\n",
    "\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "\n",
    "            \n",
    "onehot_data = np.array([one_hot_encode_along_channel_axis(seq) for seq in example_sequences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = pytorch_model(torch.tensor(onehot_data.astype(\"float32\"))).detach().numpy()\n",
    "interpretation_model = create_interpretation_model(pytorch_model,65, prenonlinearity=True)\n",
    "out2 = interpretation_model(torch.tensor(onehot_data.astype(\"float32\"))).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.1442165e-01 7.3527199e-01 7.6854521e-01 ... 8.9137870e-01\n",
      "  2.0305334e-02 7.7324861e-05]\n",
      " [8.5935098e-01 8.8919538e-01 8.9216346e-01 ... 9.9293751e-01\n",
      "  6.0476321e-01 7.9107616e-04]]\n",
      "[[2.7659173]\n",
      " [2.9149015]]\n",
      "Sequential(\n",
      "  (0): ReCodeAlphabet()\n",
      "  (1): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
      "  (2): Threshold(threshold=0, value=1e-06)\n",
      "  (3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Dropout(p=0.2)\n",
      "  (5): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
      "  (6): Threshold(threshold=0, value=1e-06)\n",
      "  (7): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.2)\n",
      "  (9): Conv2d(480, 960, kernel_size=(1, 8), stride=(1, 1))\n",
      "  (10): Threshold(threshold=0, value=1e-06)\n",
      "  (11): Dropout(p=0.5)\n",
      "  (12): Lambda()\n",
      "  (13): Lambda()\n",
      "  (14): Linear(in_features=50880, out_features=925, bias=True)\n",
      "  (15): Threshold(threshold=0, value=1e-06)\n",
      "  (16): Lambda()\n",
      "  (17): Linear(in_features=925, out_features=919, bias=True)\n",
      "  (18): Lambda()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(out1)\n",
    "print(out2)\n",
    "print(interpretation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: ReCodeAlphabet; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: Lambda; using regular gradients\n",
      "Warning: unrecognized nn.Module: ReCodeAlphabet; using regular gradients\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import importlib\n",
    "from importlib import reload\n",
    "reload(shap.explainers.deep.deep_pytorch)\n",
    "reload(shap.explainers.deep)\n",
    "reload(shap.explainers)\n",
    "reload(shap)\n",
    "import torch\n",
    "\n",
    "e = shap.DeepExplainer(interpretation_model, torch.tensor(np.zeros((1,4,1,1000)).astype(\"float32\")))\n",
    "explanation = e.shap_values(torch.tensor(onehot_data.astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.154758927599687\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(explanation[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
